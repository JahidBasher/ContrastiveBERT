{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import BERTDataset\n",
    "from tokenizer.tokenizers import ContrastiveTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = ContrastiveTokenizer(\n",
    "    tokenizer_path=\"dictionary/bn_en\",\n",
    "    vocab_size=16000,\n",
    "    max_token_length=9,\n",
    "    pad_token=\"<pad>\",\n",
    "    unk_token=\"<unk>\",\n",
    "    start_token=\"<ben>\",\n",
    "    end_token=\"</ben>\",\n",
    ")\n",
    "tk.load_from_disk(\"tokenizer/dictionary/bn_en.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset: 33036862it [00:38, 866164.00it/s] \n"
     ]
    }
   ],
   "source": [
    "dataset = SimBERTDataset(\n",
    "    corpus_path=\"/mnt/JaHiD/Zahid/RnD/ContrastiveBERT/bn_translator_data/dataset/BPCC-combined/combined/eng_Latn-ben_Beng/combined\",\n",
    "    tokenizer=tk,\n",
    "    seq_len=128,\n",
    "    padding=False,\n",
    "    encoding=\"utf-8\",\n",
    "    corpus_lines=0,\n",
    "    on_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = None\n",
    "for d in dataset:\n",
    "    x = d\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bert_input': tensor([    2, 14401,   124, 15882,   488, 14401,   124,  5867, 11855,   676,\n",
       "            146,  8383,   319,  8400, 15925,  4285, 15925, 15891, 10394,     4,\n",
       "           3109, 13545,  3898,  6075, 15898, 15884,     3]),\n",
       "  'bert_label': tensor([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0, 8718,    0,    0,    0,    0,\n",
       "             0,    0,    0]),\n",
       "  'segment_label': tensor(0.)},\n",
       " {'bert_input': tensor([    6,  8769, 13692, 15946,  1270,  6663,  1655, 15892,  8769, 13692,\n",
       "          15936, 15861,  5610, 13638,     1, 14735,  1441,   888, 14252,  3967,\n",
       "           1524,  3020,   144,  9392, 15879,     7]),\n",
       "  'bert_label': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0]),\n",
       "  'segment_label': tensor(1.)}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'তামিলনাড়ু - তামিলনাড়ুতে ৬০ দিন পর বৃহস্পতিবার কোভিড-১৯-এ দৈনিক সংক্রমণ ১০ হাজারের<mask> নেমেছ।'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.tokenizer.decode([    2, 14401,   124, 15882,   488, 14401,   124,  5867, 11855,   676,\n",
    "            146,  8383,   319,  8400, 15925,  4285, 15925, 15891, 10394,  8718,\n",
    "           3109, 13545,     4,  6075, 15898, 15884,     3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<en> Tamil Nadu: After 60 days, Tamil Nadu’s daily<mask><mask><mask> case count dropped below 10,000 on Thursday.</en>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.tokenizer.decode([    6,  8769, 13692, 15946,  1270,  6663,  1655, 15892,  8769, 13692,\n",
    "          15936, 15861,  5610,     4,     4,     4,  1441,   888, 14252,  3967,\n",
    "           1524,  3020,   144,  9392, 15879,     7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "\n",
    "    bn_bert_input, en_bert_input = [], []\n",
    "    bn_bert_label, en_bert_label = [], []\n",
    "    bn_segment_label, en_segment_label = [], []\n",
    "\n",
    "    for items in batch:\n",
    "        bn_bert_input.append(items[0]['bert_input'])\n",
    "        en_bert_input.append(items[1]['bert_input'])\n",
    "\n",
    "\n",
    "        bn_bert_label.append(items[0]['bert_label'])\n",
    "        en_bert_label.append(items[1]['bert_label'])\n",
    "\n",
    "        bn_segment_label.append(items[0]['segment_label'])\n",
    "        en_segment_label.append(items[1]['segment_label'])\n",
    "\n",
    "\n",
    "    bn_bert_input += en_bert_input\n",
    "    bn_bert_label += en_bert_label\n",
    "    bn_segment_label += en_segment_label\n",
    "\n",
    "    max_length = max(len(seq) for seq in bn_bert_input)\n",
    "\n",
    "    # Pad sequences in the batch\n",
    "    padded_bert_inputs = [\n",
    "        torch.nn.functional.pad(seq, pad=(0, max_length - len(seq)), value=0)\n",
    "        for seq in bn_bert_input\n",
    "    ]\n",
    "    padded_bert_labels = [\n",
    "        torch.nn.functional.pad(seq, pad=(0, max_length - len(seq)), value=0)\n",
    "        for seq in bn_bert_label\n",
    "    ]\n",
    "\n",
    "    # Stack the padded sequences along the batch dimension\n",
    "    padded_bert_inputs = torch.stack(padded_bert_inputs)\n",
    "    padded_bert_labels = torch.stack(padded_bert_labels)\n",
    "    segment_labels = torch.stack(bn_segment_label)\n",
    "\n",
    "    attention_mask = (padded_bert_inputs != 0).float()\n",
    "\n",
    "    return {\n",
    "        \"bert_input\": padded_bert_inputs,\n",
    "        \"bert_label\": padded_bert_labels,\n",
    "        \"segment_label\": segment_labels,\n",
    "        \"attention_mask\": attention_mask\n",
    "    }\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=2, collate_fn=collate_fn)#, prefetch_factor=2)\n",
    "for data in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert_input': tensor([[    2, 14401,   124, 15882,   488, 14401,   124,  5867, 11855,   676,\n",
       "            146,     4,     4,     4,     4,     4,     4,     4, 10394,  8718,\n",
       "           3109, 13545,  3898,  6075, 15898, 15884,     3,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    2,   396,  2587,   532, 14459,   662,   850,  1833,  2810, 15862,\n",
       "           1307,  8985,  3461,     4,   823,  4851,  4170,  5456,   560,  1584,\n",
       "          12912, 15877,   211, 15967,     4,  5873, 15898,  1066, 15889,   560,\n",
       "            475, 15892,  2060,   227,  6297,   579,   860,     4,   181,   204,\n",
       "            788,  6166,   105, 15889, 15884,     3,     0,     0,     0],\n",
       "         [    6,  8769, 13692, 15946,  1270,  6663,  1655, 15892,  8769, 13692,\n",
       "          15936, 15861,  5610, 13638,     1, 14735,  1441,   888, 14252,  3967,\n",
       "           1524,  3020,   144,  9392, 15879,     7,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    6,   561,   272,  3370,   523,  6447,   601,  9466,  2703,  2446,\n",
       "            160,    81,  1567,   148, 15848,  6483,    63,  9309,  6447,   429,\n",
       "            430, 11306,  7297,  1462,    21,  2253,   137,  3652,  1464,   180,\n",
       "          15892,     4,   282,   500,     4,   629,   398,  1954,    63,  5953,\n",
       "             46,  2277,    57,    11,  4830,   655,  1691, 15879,     7]]),\n",
       " 'bert_label': tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,  8383,   319,  8400, 15925,  4285, 15925, 15891,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    0,     0,     0,     0,     0,   662,   850,  1833,     0,     0,\n",
       "              0,     0,     0,   216,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,  1191,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,   100,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0, 14252,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,   192,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,  1286,     0,     0,   386,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0]]),\n",
       " 'segment_label': tensor([0., 0., 1., 1.]),\n",
       " 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "labels = torch.cat([torch.arange(32) for i in range(2)], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.cat(images, dim=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt1.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
